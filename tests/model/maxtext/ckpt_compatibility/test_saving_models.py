"""This test validates the bidirectional conversion of model weights
between MaxText and HuggingFace implementations. 

Steps:
    1. Load the HuggingFace model into MaxText
    2. Save the MaxText model in HuggingFace format
    3. Load the saved model into a HuggingFace model
    4. Comparing weights and outputs with the original HuggingFace model

Metrics: 
    Max absolute difference between model weights.
    Max absolute difference between the logits for the first 5 tokens.
    Disagreement among top1 tokens.

Usage: 
    Run script on single host VM: RUN_SKIPPED_TESTS=1 python -m unittest tests/model/maxtext/ckpt_compatibility/test_saving_models.py
"""

import unittest
import os
import shutil
import torch
from kithara import MaxTextModel
from transformers import AutoModelForCausalLM, AutoTokenizer
from kithara.utils.gcs_utils import find_cache_root_dir
from tests.model.utils import (
    check_arrays_match,
    check_predicted_tokens_match,
)
from tests.model.test_prompt import TEST_PROMPT

os.environ["KERAS_BACKEND"] = "jax"

class TestSavingModels(unittest.TestCase):
    """Test suite for validating bidirectional conversion of model weights between MaxText and HuggingFace."""
    
    @classmethod
    def setUpClass(cls):
        """Set up test environment."""
        cls.TMP_DIR = os.path.join(find_cache_root_dir(), "test/ckpt")
        cls.MAX_TARGET_LENGTH = 512
    
    def setUp(self):
        shutil.rmtree(self.TMP_DIR, ignore_errors=True)
        
    def tearDown(self):
        shutil.rmtree(self.TMP_DIR, ignore_errors=True)

    def _get_all_modules(self, model):
        """Get all weights names from a HF model."""
        modules = []
        for name, _ in model.named_modules():
            if name and hasattr(model.get_submodule(name), "weight"):
                modules.append(name)
        return modules

    def _check_weights_match(self, model, golden_model, tol):
        """Compare weights between two HF models."""
        modules = self._get_all_modules(golden_model)
        
        for module in modules:
            golden_weights = golden_model.get_submodule(module).state_dict()["weight"]
            model_weight = model.get_submodule(module).state_dict()["weight"]
            check_arrays_match(golden_weights, model_weight, tol)

    def _get_logits(self, model_id, model, golden_model):
        """Get logits from two HF models for comparison."""
        tokenizer = AutoTokenizer.from_pretrained(model_id)
        inputs = tokenizer.encode(TEST_PROMPT, return_tensors="pt")[:, :self.MAX_TARGET_LENGTH]

        logits = model(inputs, output_hidden_states=True).logits
        golden_logits = golden_model(inputs, output_hidden_states=True).logits

        return logits, golden_logits

    def _run_conversion_test(self, model_id, weight_tol, logits_tol, top1_token_tol):
        # Create Model
        model = MaxTextModel.from_preset(
            preset_handle=f"hf://{model_id}",
            seq_len=self.MAX_TARGET_LENGTH,
            per_device_batch_size=1,
            scan_layers=True,
            precision="mixed_float16",
        )

        # Save model
        model.save_in_hf_format(self.TMP_DIR)

        # Load model
        model = AutoModelForCausalLM.from_pretrained(self.TMP_DIR, torch_dtype=torch.float32)

        # Load reference model
        golden_model = AutoModelForCausalLM.from_pretrained(
            model_id, torch_dtype=torch.float32
        )
        
        # Check weights match
        self._check_weights_match(model, golden_model, weight_tol)

        # Run forward pass to get logits
        logits, golden_logits = self._get_logits(model_id, model, golden_model)

        # Check logits from the first 5 tokens match
        check_arrays_match(logits[0, :5, :], golden_logits[0, :5, :], logits_tol)
        check_predicted_tokens_match(logits, golden_logits, top1_token_tol)

    @unittest.skipIf(int(os.getenv('RUN_SKIPPED_TESTS', 0)) != 1, "Manual Test")
    def test_gemma_2b_conversion(self):
        """Test conversion for Gemma 2B model."""
        self._run_conversion_test(
            model_id="google/gemma-2-2b",
            weight_tol=0.0001,
            logits_tol=0.0001,
            top1_token_tol=0.0001
        )

    @unittest.skipIf(int(os.getenv('RUN_SKIPPED_TESTS', 0)) != 1, "Manual Test")
    def test_gemma_9b_conversion(self):
        """Test conversion for Gemma 9B model."""
        self._run_conversion_test(
            model_id="google/gemma-2-9b",
            weight_tol=0.0001,
            logits_tol=2.0,
            top1_token_tol=0.1
        )

if __name__ == '__main__':
    unittest.main(verbosity=2)
